{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,RepeatedKFold, GridSearchCV,  RandomizedSearchCV\n",
    "import math\n",
    "from data import *\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Decomposition\n",
    "- Goal 0: System type classification\n",
    "- Goal 1: Primary & Secondary decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flux_0</th>\n",
       "      <th>flux_1</th>\n",
       "      <th>flux_2</th>\n",
       "      <th>flux_3</th>\n",
       "      <th>flux_4</th>\n",
       "      <th>flux_5</th>\n",
       "      <th>flux_6</th>\n",
       "      <th>flux_7</th>\n",
       "      <th>flux_8</th>\n",
       "      <th>flux_9</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_434</th>\n",
       "      <th>flux_435</th>\n",
       "      <th>flux_436</th>\n",
       "      <th>flux_437</th>\n",
       "      <th>flux_438</th>\n",
       "      <th>flux_439</th>\n",
       "      <th>flux_440</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>secondary_type</th>\n",
       "      <th>system_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568345</td>\n",
       "      <td>0.615487</td>\n",
       "      <td>0.668477</td>\n",
       "      <td>0.705189</td>\n",
       "      <td>0.698754</td>\n",
       "      <td>0.700950</td>\n",
       "      <td>0.717146</td>\n",
       "      <td>0.704941</td>\n",
       "      <td>0.707754</td>\n",
       "      <td>0.723033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209508</td>\n",
       "      <td>0.203912</td>\n",
       "      <td>0.205196</td>\n",
       "      <td>0.201559</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.209226</td>\n",
       "      <td>0.214793</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496365</td>\n",
       "      <td>0.563067</td>\n",
       "      <td>0.602393</td>\n",
       "      <td>0.659527</td>\n",
       "      <td>0.682808</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>0.674343</td>\n",
       "      <td>0.689054</td>\n",
       "      <td>0.676825</td>\n",
       "      <td>0.670386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213932</td>\n",
       "      <td>0.207528</td>\n",
       "      <td>0.206223</td>\n",
       "      <td>0.201853</td>\n",
       "      <td>0.205284</td>\n",
       "      <td>0.206424</td>\n",
       "      <td>0.206224</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520227</td>\n",
       "      <td>0.580531</td>\n",
       "      <td>0.627045</td>\n",
       "      <td>0.645281</td>\n",
       "      <td>0.665795</td>\n",
       "      <td>0.678923</td>\n",
       "      <td>0.686509</td>\n",
       "      <td>0.685623</td>\n",
       "      <td>0.674414</td>\n",
       "      <td>0.702066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187648</td>\n",
       "      <td>0.184240</td>\n",
       "      <td>0.177598</td>\n",
       "      <td>0.175445</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.181286</td>\n",
       "      <td>0.176042</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.483774</td>\n",
       "      <td>0.556865</td>\n",
       "      <td>0.603915</td>\n",
       "      <td>0.641451</td>\n",
       "      <td>0.698212</td>\n",
       "      <td>0.728678</td>\n",
       "      <td>0.666010</td>\n",
       "      <td>0.671234</td>\n",
       "      <td>0.659358</td>\n",
       "      <td>0.688617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233598</td>\n",
       "      <td>0.225866</td>\n",
       "      <td>0.234960</td>\n",
       "      <td>0.214639</td>\n",
       "      <td>0.219380</td>\n",
       "      <td>0.224144</td>\n",
       "      <td>0.224282</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.434787</td>\n",
       "      <td>0.504214</td>\n",
       "      <td>0.543165</td>\n",
       "      <td>0.611378</td>\n",
       "      <td>0.659270</td>\n",
       "      <td>0.680497</td>\n",
       "      <td>0.663214</td>\n",
       "      <td>0.634306</td>\n",
       "      <td>0.645955</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218515</td>\n",
       "      <td>0.209248</td>\n",
       "      <td>0.202981</td>\n",
       "      <td>0.198711</td>\n",
       "      <td>0.201315</td>\n",
       "      <td>0.201008</td>\n",
       "      <td>0.202865</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110809</th>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>-0.001549</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>-0.001746</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110810</th>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>0.010406</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110848</th>\n",
       "      <td>0.073538</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>-0.005860</td>\n",
       "      <td>-0.038976</td>\n",
       "      <td>-0.014792</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.009587</td>\n",
       "      <td>0.015874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>-0.005274</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110849</th>\n",
       "      <td>0.001377</td>\n",
       "      <td>-0.014757</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>-0.003643</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.007200</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110887</th>\n",
       "      <td>0.054611</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.029133</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>-0.011670</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>-0.000691</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>-0.003753</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38449 rows × 444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          flux_0    flux_1    flux_2    flux_3    flux_4    flux_5    flux_6  \\\n",
       "0       0.568345  0.615487  0.668477  0.705189  0.698754  0.700950  0.717146   \n",
       "1       0.496365  0.563067  0.602393  0.659527  0.682808  0.676481  0.674343   \n",
       "2       0.520227  0.580531  0.627045  0.645281  0.665795  0.678923  0.686509   \n",
       "3       0.483774  0.556865  0.603915  0.641451  0.698212  0.728678  0.666010   \n",
       "4       0.434787  0.504214  0.543165  0.611378  0.659270  0.680497  0.663214   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110809  0.030098  0.014580 -0.007441 -0.006942 -0.007369  0.006425  0.016458   \n",
       "110810  0.005596  0.004737 -0.002069  0.010406  0.006171  0.009747  0.011305   \n",
       "110848  0.073538  0.009197 -0.005860 -0.038976 -0.014792 -0.014072  0.036644   \n",
       "110849  0.001377 -0.014757 -0.004499  0.012407 -0.003643 -0.001074  0.012893   \n",
       "110887  0.054611  0.005404 -0.005459 -0.029133 -0.010909 -0.011670  0.031216   \n",
       "\n",
       "          flux_7    flux_8    flux_9  ...  flux_434  flux_435  flux_436  \\\n",
       "0       0.704941  0.707754  0.723033  ...  0.209508  0.203912  0.205196   \n",
       "1       0.689054  0.676825  0.670386  ...  0.213932  0.207528  0.206223   \n",
       "2       0.685623  0.674414  0.702066  ...  0.187648  0.184240  0.177598   \n",
       "3       0.671234  0.659358  0.688617  ...  0.233598  0.225866  0.234960   \n",
       "4       0.634306  0.645955  0.654454  ...  0.218515  0.209248  0.202981   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "110809  0.006826 -0.001549  0.020413  ... -0.000636 -0.005062 -0.001746   \n",
       "110810  0.008200  0.004347  0.014751  ... -0.001543 -0.004403  0.001089   \n",
       "110848 -0.001032 -0.009587  0.015874  ...  0.003452 -0.007673 -0.005274   \n",
       "110849 -0.004316  0.009678 -0.000535  ... -0.000068 -0.007200  0.002112   \n",
       "110887 -0.000691 -0.006766  0.012228  ...  0.001485 -0.007395 -0.003753   \n",
       "\n",
       "        flux_437  flux_438  flux_439  flux_440  primary_type  secondary_type  \\\n",
       "0       0.201559  0.207766  0.209226  0.214793          16.0            16.0   \n",
       "1       0.201853  0.205284  0.206424  0.206224          16.0            17.0   \n",
       "2       0.175445  0.175319  0.181286  0.176042          16.0            16.0   \n",
       "3       0.214639  0.219380  0.224144  0.224282          16.0            16.0   \n",
       "4       0.198711  0.201315  0.201008  0.202865          16.0            16.0   \n",
       "...          ...       ...       ...       ...           ...             ...   \n",
       "110809  0.002502  0.002527  0.002917  0.003646          38.0            38.0   \n",
       "110810  0.004393  0.004432  0.004561 -0.000681          38.0            39.0   \n",
       "110848  0.000802  0.001512  0.001638  0.005702          38.0            38.0   \n",
       "110849  0.005037  0.006211  0.005238 -0.004113          38.0            39.0   \n",
       "110887  0.002067  0.002337  0.001898  0.004502          38.0            39.0   \n",
       "\n",
       "        system_type  \n",
       "0              16.0  \n",
       "1              16.0  \n",
       "2              16.0  \n",
       "3              16.0  \n",
       "4              16.0  \n",
       "...             ...  \n",
       "110809         38.0  \n",
       "110810         38.0  \n",
       "110848         38.0  \n",
       "110849         39.0  \n",
       "110887         38.0  \n",
       "\n",
       "[38449 rows x 444 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_hdf('/Users/lukemcdermott/Desktop/Physics/spectral_templates_data_version_june20.h5', key = '/binaries')\n",
    "bin_df = pd.read_hdf('/Users/lukemcdermott/Desktop/Physics/spectral_templates_data_version_june20.h5', key = '/binaries')\n",
    "df = df.loc[df['primary_type'] <= df['secondary_type']]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30759\n"
     ]
    }
   ],
   "source": [
    "x = np.insert(np.arange(441), 0, 443)\n",
    "images = df.iloc[:, :441].to_numpy()\n",
    "labels = df.iloc[:, 441:443].to_numpy()\n",
    "labels_flat = np.zeros((len(labels)))\n",
    "for idx, i in enumerate(labels):\n",
    "    labels_flat[idx] = 24*(int(i[0]-16)) + int((i[1]-16))\n",
    "\n",
    "    \n",
    "# Split into training and testing sets\n",
    "train_images, train_labels, test_images, test_labels = split_data(images, labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', multi_class='multinomial')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', class_weight = 'balanced')\n",
    "model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13797139141742523"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Distance Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(test_images)\n",
    "vout = np.zeros((len(outputs), 2))\n",
    "vlab = np.zeros((len(outputs), 2))\n",
    "loss = np.zeros((len(outputs)))\n",
    "for i in range(len(outputs)):\n",
    "    vout[i] = np.array([(int(outputs[i]//24)) + 16, outputs[i] - int(outputs[i]//24)*24 + 16])\n",
    "    vlab[i] = np.array([(int(test_labels[i]//24)) + 16, test_labels[i] - int(test_labels[i]//24)*24 + 16])\n",
    "    loss[i] = ((vout[i]-vlab[i])**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41421356 4.24264069 0.70710678 3.53553391 0.70710678]\n",
      "[[17. 37.]\n",
      " [19. 27.]\n",
      " [20. 21.]\n",
      " [20. 31.]\n",
      " [19. 24.]]\n",
      "[[17. 35.]\n",
      " [19. 21.]\n",
      " [21. 21.]\n",
      " [20. 36.]\n",
      " [19. 25.]]\n",
      "average loss: 3.2760698382639917\n",
      "num with loss <= 0 0.13797139141742523\n",
      "num with loss <= 1 0.34655396618985695\n",
      "num with loss <= 2 0.47230169050715215\n",
      "num with loss <= 3 0.6150845253576073\n",
      "num with loss <= 4 0.6864759427828349\n",
      "num with loss <= 5 0.7624187256176853\n"
     ]
    }
   ],
   "source": [
    "print(loss[:5])\n",
    "print(vout[:5])\n",
    "print(vlab[:5])\n",
    "print('average loss:', np.mean(loss))\n",
    "print('num with loss <= 0', np.sum(loss <= 0) / len(outputs))\n",
    "print('num with loss <= 1', np.sum(loss <= 1) / len(outputs))\n",
    "print('num with loss <= 2', np.sum(loss <= 2) / len(outputs))\n",
    "print('num with loss <= 3', np.sum(loss <= 3) / len(outputs))\n",
    "print('num with loss <= 4', np.sum(loss <= 4) / len(outputs))\n",
    "print('num with loss <= 5', np.sum(loss <= 5) / len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does this guess separation? ex: 16,34 has large separation... 20,20 has none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros((len(outputs)))\n",
    "for i in range(len(outputs)):\n",
    "    d[i] = abs( abs(vout[i,0] - vout[i,1]) - abs(vlab[i,0] - vlab[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 1. 5. 1.]\n",
      "average d: 4.425747724317295\n"
     ]
    }
   ],
   "source": [
    "print(d[:5])\n",
    "print('average d:', np.mean(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lukemcdermott/Desktop/Physics/Star-Lab/binary-decomposition.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lukemcdermott/Desktop/Physics/Star-Lab/binary-decomposition.ipynb#ch0000004?line=0'>1</a>\u001b[0m best_model \u001b[39m=\u001b[39m RandomForestClassifier(random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, criterion \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#BalancedRandomForestClassifier(random_state=0)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lukemcdermott/Desktop/Physics/Star-Lab/binary-decomposition.ipynb#ch0000004?line=1'>2</a>\u001b[0m best_model\u001b[39m.\u001b[39;49mfit(train_images, train_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lukemcdermott/Desktop/Physics/Star-Lab/binary-decomposition.ipynb#ch0000004?line=2'>3</a>\u001b[0m accuracy \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mscore(test_images, test_labels)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m )(\n\u001b[1;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    482\u001b[0m         t,\n\u001b[1;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    484\u001b[0m         X,\n\u001b[1;32m    485\u001b[0m         y,\n\u001b[1;32m    486\u001b[0m         sample_weight,\n\u001b[1;32m    487\u001b[0m         i,\n\u001b[1;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(random_state = 0, criterion = \"entropy\") #BalancedRandomForestClassifier(random_state=0)\n",
    "best_model.fit(train_images, train_labels)\n",
    "accuracy = best_model.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7573196857890978\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 1100, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 60, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               \n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1100; total time=16.5min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1100; total time=16.6min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time=27.9min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time=28.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukemcdermott/mambaforge/envs/sklearn-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=0),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 60, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 1100, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=0),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 60, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 1100, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    random_state=0),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 60, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 1100, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state = 0, criterion = \"entropy\")\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607712449416806"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = rf_random.predict_proba(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_random.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0 32.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([14.,  5.,  1.,  1.,  0.,  0.,  2.,  0.,  0.,  1.]),\n",
       " array([0.001     , 0.02501924, 0.04903848, 0.07305773, 0.09707697,\n",
       "        0.12109621, 0.14511545, 0.1691347 , 0.19315394, 0.21717318,\n",
       "        0.24119242]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred[13], test_labels[13])\n",
    "plt.hist(prob[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "12\n",
      "13\n",
      "18\n",
      "20\n",
      "21\n",
      "28\n",
      "34\n",
      "41\n",
      "43\n",
      "50\n",
      "53\n",
      "55\n",
      "56\n",
      "61\n",
      "68\n",
      "78\n",
      "82\n",
      "88\n",
      "95\n",
      "96\n",
      "98\n",
      "102\n",
      "109\n",
      "110\n",
      "111\n",
      "122\n",
      "125\n",
      "130\n",
      "132\n",
      "133\n",
      "134\n",
      "136\n",
      "143\n",
      "149\n",
      "150\n",
      "154\n",
      "165\n",
      "167\n",
      "169\n",
      "171\n",
      "173\n",
      "178\n",
      "180\n",
      "192\n",
      "202\n",
      "204\n",
      "210\n",
      "212\n",
      "217\n",
      "218\n",
      "226\n",
      "235\n",
      "237\n",
      "241\n",
      "243\n",
      "248\n",
      "250\n",
      "253\n",
      "254\n",
      "261\n",
      "262\n",
      "266\n",
      "269\n",
      "274\n",
      "275\n",
      "276\n",
      "283\n",
      "285\n",
      "287\n",
      "294\n",
      "295\n",
      "305\n",
      "315\n",
      "328\n",
      "340\n",
      "341\n",
      "346\n",
      "354\n",
      "361\n",
      "362\n",
      "370\n",
      "376\n",
      "379\n",
      "382\n",
      "385\n",
      "387\n",
      "396\n",
      "399\n",
      "401\n",
      "403\n",
      "404\n",
      "410\n",
      "417\n",
      "419\n",
      "428\n",
      "436\n",
      "445\n",
      "447\n",
      "455\n",
      "456\n",
      "460\n",
      "464\n",
      "467\n",
      "469\n",
      "480\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "493\n",
      "496\n",
      "504\n",
      "508\n",
      "514\n",
      "519\n",
      "521\n",
      "525\n",
      "531\n",
      "535\n",
      "540\n",
      "553\n",
      "556\n",
      "557\n",
      "561\n",
      "566\n",
      "567\n",
      "572\n",
      "576\n",
      "577\n",
      "580\n",
      "589\n",
      "596\n",
      "598\n",
      "600\n",
      "605\n",
      "621\n",
      "627\n",
      "631\n",
      "636\n",
      "639\n",
      "645\n",
      "646\n",
      "654\n",
      "656\n",
      "658\n",
      "662\n",
      "666\n",
      "668\n",
      "675\n",
      "680\n",
      "682\n",
      "690\n",
      "694\n",
      "699\n",
      "701\n",
      "704\n",
      "706\n",
      "711\n",
      "716\n",
      "718\n",
      "722\n",
      "724\n",
      "739\n",
      "740\n",
      "741\n",
      "745\n",
      "748\n",
      "750\n",
      "751\n",
      "754\n",
      "758\n",
      "763\n",
      "764\n",
      "765\n",
      "771\n",
      "774\n",
      "776\n",
      "780\n",
      "782\n",
      "791\n",
      "797\n",
      "800\n",
      "801\n",
      "807\n",
      "810\n",
      "812\n",
      "821\n",
      "832\n",
      "838\n",
      "839\n",
      "842\n",
      "844\n",
      "845\n",
      "846\n",
      "850\n",
      "856\n",
      "858\n",
      "860\n",
      "863\n",
      "870\n",
      "872\n",
      "873\n",
      "884\n",
      "887\n",
      "890\n",
      "895\n",
      "896\n",
      "899\n",
      "903\n",
      "907\n",
      "911\n",
      "914\n",
      "915\n",
      "922\n",
      "931\n",
      "935\n",
      "946\n",
      "947\n",
      "951\n",
      "955\n",
      "959\n",
      "966\n",
      "967\n",
      "970\n",
      "971\n",
      "973\n",
      "980\n",
      "984\n",
      "990\n",
      "991\n",
      "995\n",
      "997\n",
      "998\n",
      "999\n",
      "1004\n",
      "1006\n",
      "1016\n",
      "1017\n",
      "1022\n",
      "1025\n",
      "1027\n",
      "1031\n",
      "1035\n",
      "1042\n",
      "1046\n",
      "1047\n",
      "1055\n",
      "1057\n",
      "1064\n",
      "1066\n",
      "1071\n",
      "1097\n",
      "1100\n",
      "1102\n",
      "1103\n",
      "1105\n",
      "1112\n",
      "1115\n",
      "1117\n",
      "1124\n",
      "1127\n",
      "1130\n",
      "1132\n",
      "1139\n",
      "1145\n",
      "1150\n",
      "1152\n",
      "1153\n",
      "1157\n",
      "1160\n",
      "1162\n",
      "1164\n",
      "1165\n",
      "1170\n",
      "1176\n",
      "1177\n",
      "1179\n",
      "1182\n",
      "1183\n",
      "1186\n",
      "1191\n",
      "1194\n",
      "1202\n",
      "1205\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1224\n",
      "1235\n",
      "1236\n",
      "1249\n",
      "1253\n",
      "1258\n",
      "1266\n",
      "1274\n",
      "1280\n",
      "1282\n",
      "1308\n",
      "1309\n",
      "1311\n",
      "1313\n",
      "1315\n",
      "1320\n",
      "1322\n",
      "1325\n",
      "1326\n",
      "1339\n",
      "1342\n",
      "1343\n",
      "1348\n",
      "1352\n",
      "1358\n",
      "1364\n",
      "1365\n",
      "1369\n",
      "1370\n",
      "1378\n",
      "1381\n",
      "1393\n",
      "1404\n",
      "1407\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1420\n",
      "1423\n",
      "1427\n",
      "1441\n",
      "1443\n",
      "1445\n",
      "1446\n",
      "1450\n",
      "1461\n",
      "1467\n",
      "1469\n",
      "1479\n",
      "1486\n",
      "1494\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1507\n",
      "1516\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1526\n",
      "1533\n",
      "1536\n",
      "1537\n",
      "1544\n",
      "1549\n",
      "1553\n",
      "1560\n",
      "1569\n",
      "1573\n",
      "1580\n",
      "1583\n",
      "1586\n",
      "1588\n",
      "1601\n",
      "1604\n",
      "1605\n",
      "1608\n",
      "1611\n",
      "1615\n",
      "1616\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1631\n",
      "1642\n",
      "1647\n",
      "1648\n",
      "1653\n",
      "1654\n",
      "1656\n",
      "1659\n",
      "1666\n",
      "1671\n",
      "1681\n",
      "1684\n",
      "1687\n",
      "1688\n",
      "1692\n",
      "1698\n",
      "1702\n",
      "1713\n",
      "1718\n",
      "1720\n",
      "1727\n",
      "1733\n",
      "1742\n",
      "1745\n",
      "1750\n",
      "1753\n",
      "1756\n",
      "1757\n",
      "1759\n",
      "1760\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1775\n",
      "1782\n",
      "1788\n",
      "1789\n",
      "1792\n",
      "1794\n",
      "1796\n",
      "1797\n",
      "1800\n",
      "1803\n",
      "1804\n",
      "1810\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1828\n",
      "1830\n",
      "1833\n",
      "1834\n",
      "1843\n",
      "1848\n",
      "1849\n",
      "1855\n",
      "1867\n",
      "1869\n",
      "1872\n",
      "1878\n",
      "1885\n",
      "1887\n",
      "1895\n",
      "1896\n",
      "1901\n",
      "1904\n",
      "1905\n",
      "1907\n",
      "1913\n",
      "1914\n",
      "1921\n",
      "1934\n",
      "1939\n",
      "1941\n",
      "1944\n",
      "1953\n",
      "1954\n",
      "1961\n",
      "1962\n",
      "1970\n",
      "1976\n",
      "1980\n",
      "1981\n",
      "1988\n",
      "1993\n",
      "1994\n",
      "1996\n",
      "1997\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2014\n",
      "2020\n",
      "2024\n",
      "2030\n",
      "2035\n",
      "2037\n",
      "2038\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2047\n",
      "2048\n",
      "2054\n",
      "2056\n",
      "2059\n",
      "2063\n",
      "2065\n",
      "2068\n",
      "2075\n",
      "2078\n",
      "2082\n",
      "2083\n",
      "2087\n",
      "2095\n",
      "2098\n",
      "2100\n",
      "2104\n",
      "2106\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2114\n",
      "2116\n",
      "2118\n",
      "2128\n",
      "2130\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2143\n",
      "2144\n",
      "2148\n",
      "2149\n",
      "2154\n",
      "2164\n",
      "2168\n",
      "2196\n",
      "2198\n",
      "2200\n",
      "2205\n",
      "2207\n",
      "2209\n",
      "2214\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2232\n",
      "2235\n",
      "2238\n",
      "2239\n",
      "2265\n",
      "2268\n",
      "2269\n",
      "2271\n",
      "2274\n",
      "2278\n",
      "2282\n",
      "2286\n",
      "2290\n",
      "2292\n",
      "2297\n",
      "2300\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2314\n",
      "2320\n",
      "2324\n",
      "2339\n",
      "2346\n",
      "2347\n",
      "2351\n",
      "2358\n",
      "2359\n",
      "2367\n",
      "2370\n",
      "2374\n",
      "2380\n",
      "2382\n",
      "2384\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2397\n",
      "2399\n",
      "2401\n",
      "2405\n",
      "2407\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2421\n",
      "2426\n",
      "2427\n",
      "2438\n",
      "2441\n",
      "2443\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2451\n",
      "2452\n",
      "2455\n",
      "2458\n",
      "2459\n",
      "2465\n",
      "2479\n",
      "2482\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2499\n",
      "2502\n",
      "2503\n",
      "2507\n",
      "2509\n",
      "2510\n",
      "2514\n",
      "2517\n",
      "2520\n",
      "2533\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2543\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2562\n",
      "2569\n",
      "2574\n",
      "2577\n",
      "2580\n",
      "2585\n",
      "2588\n",
      "2596\n",
      "2597\n",
      "2604\n",
      "2614\n",
      "2616\n",
      "2625\n",
      "2626\n",
      "2628\n",
      "2629\n",
      "2632\n",
      "2634\n",
      "2639\n",
      "2640\n",
      "2642\n",
      "2643\n",
      "2652\n",
      "2657\n",
      "2658\n",
      "2661\n",
      "2663\n",
      "2667\n",
      "2671\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2684\n",
      "2686\n",
      "2688\n",
      "2698\n",
      "2699\n",
      "2704\n",
      "2705\n",
      "2709\n",
      "2714\n",
      "2717\n",
      "2719\n",
      "2720\n",
      "2723\n",
      "2727\n",
      "2732\n",
      "2735\n",
      "2740\n",
      "2748\n",
      "2750\n",
      "2751\n",
      "2753\n",
      "2759\n",
      "2765\n",
      "2766\n",
      "2769\n",
      "2775\n",
      "2776\n",
      "2781\n",
      "2784\n",
      "2788\n",
      "2790\n",
      "2791\n",
      "2798\n",
      "2799\n",
      "2803\n",
      "2805\n",
      "2813\n",
      "2815\n",
      "2827\n",
      "2835\n",
      "2838\n",
      "2841\n",
      "2844\n",
      "2845\n",
      "2850\n",
      "2852\n",
      "2854\n",
      "2855\n",
      "2857\n",
      "2860\n",
      "2863\n",
      "2864\n",
      "2868\n",
      "2876\n",
      "2877\n",
      "2879\n",
      "2882\n",
      "2883\n",
      "2885\n",
      "2892\n",
      "2893\n",
      "2898\n",
      "2902\n",
      "2909\n",
      "2919\n",
      "2921\n",
      "2931\n",
      "2938\n",
      "2943\n",
      "2945\n",
      "2947\n",
      "2950\n",
      "2951\n",
      "2955\n",
      "2959\n",
      "2962\n",
      "2968\n",
      "2995\n",
      "3002\n",
      "3004\n",
      "3005\n",
      "3007\n",
      "3012\n",
      "3016\n",
      "3017\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3032\n",
      "3042\n",
      "3046\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3058\n",
      "3062\n",
      "3068\n",
      "3076\n",
      "3079\n",
      "3086\n",
      "3087\n",
      "3089\n",
      "3095\n",
      "3099\n",
      "3101\n",
      "3108\n",
      "3112\n",
      "3114\n",
      "3115\n",
      "3121\n",
      "3122\n",
      "3128\n",
      "3131\n",
      "3136\n",
      "3139\n",
      "3140\n",
      "3145\n",
      "3146\n",
      "3151\n",
      "3153\n",
      "3164\n",
      "3168\n",
      "3186\n",
      "3188\n",
      "3190\n",
      "3192\n",
      "3198\n",
      "3200\n",
      "3206\n",
      "3207\n",
      "3218\n",
      "3226\n",
      "3229\n",
      "3231\n",
      "3233\n",
      "3237\n",
      "3239\n",
      "3243\n",
      "3246\n",
      "3249\n",
      "3251\n",
      "3257\n",
      "3273\n",
      "3277\n",
      "3281\n",
      "3283\n",
      "3284\n",
      "3292\n",
      "3294\n",
      "3299\n",
      "3301\n",
      "3302\n",
      "3313\n",
      "3314\n",
      "3322\n",
      "3343\n",
      "3344\n",
      "3359\n",
      "3360\n",
      "3365\n",
      "3368\n",
      "3370\n",
      "3371\n",
      "3384\n",
      "3385\n",
      "3389\n",
      "3393\n",
      "3395\n",
      "3397\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3406\n",
      "3408\n",
      "3409\n",
      "3414\n",
      "3417\n",
      "3424\n",
      "3428\n",
      "3435\n",
      "3438\n",
      "3443\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3457\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3468\n",
      "3469\n",
      "3472\n",
      "3478\n",
      "3479\n",
      "3481\n",
      "3482\n",
      "3493\n",
      "3495\n",
      "3499\n",
      "3501\n",
      "3509\n",
      "3516\n",
      "3526\n",
      "3533\n",
      "3537\n",
      "3538\n",
      "3545\n",
      "3547\n",
      "3551\n",
      "3553\n",
      "3557\n",
      "3558\n",
      "3562\n",
      "3566\n",
      "3567\n",
      "3572\n",
      "3576\n",
      "3577\n",
      "3579\n",
      "3584\n",
      "3594\n",
      "3598\n",
      "3600\n",
      "3602\n",
      "3604\n",
      "3606\n",
      "3607\n",
      "3625\n",
      "3630\n",
      "3636\n",
      "3637\n",
      "3639\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3661\n",
      "3667\n",
      "3669\n",
      "3676\n",
      "3684\n",
      "3688\n",
      "3690\n",
      "3693\n",
      "3695\n",
      "3696\n",
      "3701\n",
      "3703\n",
      "3706\n",
      "3708\n",
      "3710\n",
      "3714\n",
      "3718\n",
      "3725\n",
      "3731\n",
      "3732\n",
      "3737\n",
      "3741\n",
      "3743\n",
      "3754\n",
      "3763\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3785\n",
      "3787\n",
      "3790\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3801\n",
      "3809\n",
      "3811\n",
      "3813\n",
      "3816\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3830\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3857\n",
      "3862\n",
      "3864\n",
      "3875\n",
      "3876\n",
      "3885\n",
      "3888\n",
      "3890\n",
      "3891\n",
      "3897\n",
      "3904\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3913\n",
      "3914\n",
      "3916\n",
      "3917\n",
      "3922\n",
      "3934\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3951\n",
      "3955\n",
      "3956\n",
      "3966\n",
      "3971\n",
      "3982\n",
      "3986\n",
      "3991\n",
      "3992\n",
      "3994\n",
      "3995\n",
      "3998\n",
      "4001\n",
      "4003\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4028\n",
      "4039\n",
      "4042\n",
      "4049\n",
      "4061\n",
      "4062\n",
      "4064\n",
      "4067\n",
      "4069\n",
      "4074\n",
      "4079\n",
      "4080\n",
      "4090\n",
      "4094\n",
      "4100\n",
      "4108\n",
      "4120\n",
      "4122\n",
      "4124\n",
      "4136\n",
      "4146\n",
      "4154\n",
      "4156\n",
      "4160\n",
      "4164\n",
      "4165\n",
      "4167\n",
      "4178\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4185\n",
      "4191\n",
      "4192\n",
      "4197\n",
      "4199\n",
      "4212\n",
      "4218\n",
      "4228\n",
      "4230\n",
      "4232\n",
      "4237\n",
      "4242\n",
      "4244\n",
      "4246\n",
      "4247\n",
      "4251\n",
      "4267\n",
      "4268\n",
      "4271\n",
      "4272\n",
      "4279\n",
      "4282\n",
      "4284\n",
      "4289\n",
      "4294\n",
      "4296\n",
      "4298\n",
      "4301\n",
      "4315\n",
      "4318\n",
      "4319\n",
      "4332\n",
      "4335\n",
      "4344\n",
      "4348\n",
      "4352\n",
      "4357\n",
      "4361\n",
      "4366\n",
      "4370\n",
      "4371\n",
      "4378\n",
      "4387\n",
      "4390\n",
      "4391\n",
      "4394\n",
      "4396\n",
      "4401\n",
      "4411\n",
      "4415\n",
      "4426\n",
      "4433\n",
      "4435\n",
      "4437\n",
      "4442\n",
      "4453\n",
      "4455\n",
      "4460\n",
      "4466\n",
      "4470\n",
      "4472\n",
      "4478\n",
      "4479\n",
      "4483\n",
      "4484\n",
      "4492\n",
      "4503\n",
      "4505\n",
      "4506\n",
      "4508\n",
      "4513\n",
      "4517\n",
      "4525\n",
      "4538\n",
      "4540\n",
      "4544\n",
      "4551\n",
      "4552\n",
      "4557\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4575\n",
      "4576\n",
      "4584\n",
      "4592\n",
      "4609\n",
      "4610\n",
      "4613\n",
      "4619\n",
      "4629\n",
      "4633\n",
      "4634\n",
      "4638\n",
      "4642\n",
      "4646\n",
      "4647\n",
      "4656\n",
      "4658\n",
      "4661\n",
      "4669\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4685\n",
      "4686\n",
      "4691\n",
      "4693\n",
      "4706\n",
      "4707\n",
      "4712\n",
      "4717\n",
      "4719\n",
      "4726\n",
      "4735\n",
      "4738\n",
      "4749\n",
      "4758\n",
      "4762\n",
      "4768\n",
      "4769\n",
      "4771\n",
      "4773\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4782\n",
      "4795\n",
      "4798\n",
      "4799\n",
      "4802\n",
      "4803\n",
      "4815\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4850\n",
      "4853\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4862\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4876\n",
      "4885\n",
      "4889\n",
      "4891\n",
      "4893\n",
      "4894\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4903\n",
      "4905\n",
      "4908\n",
      "4911\n",
      "4917\n",
      "4921\n",
      "4922\n",
      "4924\n",
      "4929\n",
      "4930\n",
      "4934\n",
      "4936\n",
      "4940\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4958\n",
      "4960\n",
      "4967\n",
      "4970\n",
      "4973\n",
      "4977\n",
      "4978\n",
      "4980\n",
      "4985\n",
      "4986\n",
      "4988\n",
      "4991\n",
      "4994\n",
      "4996\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5008\n",
      "5013\n",
      "5015\n",
      "5018\n",
      "5027\n",
      "5029\n",
      "5032\n",
      "5039\n",
      "5041\n",
      "5046\n",
      "5047\n",
      "5050\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5059\n",
      "5066\n",
      "5069\n",
      "5071\n",
      "5072\n",
      "5076\n",
      "5081\n",
      "5088\n",
      "5092\n",
      "5095\n",
      "5103\n",
      "5114\n",
      "5121\n",
      "5123\n",
      "5125\n",
      "5129\n",
      "5135\n",
      "5137\n",
      "5140\n",
      "5146\n",
      "5159\n",
      "5162\n",
      "5164\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5176\n",
      "5183\n",
      "5185\n",
      "5186\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5195\n",
      "5196\n",
      "5198\n",
      "5200\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5213\n",
      "5223\n",
      "5233\n",
      "5236\n",
      "5241\n",
      "5243\n",
      "5246\n",
      "5247\n",
      "5254\n",
      "5257\n",
      "5263\n",
      "5264\n",
      "5266\n",
      "5274\n",
      "5281\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5291\n",
      "5299\n",
      "5304\n",
      "5305\n",
      "5311\n",
      "5312\n",
      "5316\n",
      "5332\n",
      "5338\n",
      "5347\n",
      "5354\n",
      "5361\n",
      "5363\n",
      "5364\n",
      "5366\n",
      "5367\n",
      "5370\n",
      "5371\n",
      "5373\n",
      "5377\n",
      "5379\n",
      "5384\n",
      "5388\n",
      "5391\n",
      "5393\n",
      "5397\n",
      "5401\n",
      "5403\n",
      "5407\n",
      "5410\n",
      "5411\n",
      "5413\n",
      "5414\n",
      "5418\n",
      "5424\n",
      "5426\n",
      "5430\n",
      "5431\n",
      "5435\n",
      "5438\n",
      "5442\n",
      "5446\n",
      "5447\n",
      "5454\n",
      "5460\n",
      "5471\n",
      "5473\n",
      "5477\n",
      "5480\n",
      "5481\n",
      "5485\n",
      "5488\n",
      "5494\n",
      "5516\n",
      "5518\n",
      "5520\n",
      "5522\n",
      "5537\n",
      "5539\n",
      "5548\n",
      "5557\n",
      "5558\n",
      "5561\n",
      "5563\n",
      "5566\n",
      "5568\n",
      "5574\n",
      "5584\n",
      "5585\n",
      "5587\n",
      "5591\n",
      "5594\n",
      "5597\n",
      "5598\n",
      "5604\n",
      "5606\n",
      "5608\n",
      "5610\n",
      "5611\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5620\n",
      "5626\n",
      "5637\n",
      "5641\n",
      "5642\n",
      "5646\n",
      "5648\n",
      "5649\n",
      "5661\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5672\n",
      "5674\n",
      "5679\n",
      "5681\n",
      "5684\n",
      "5687\n",
      "5689\n",
      "5701\n",
      "5711\n",
      "5713\n",
      "5714\n",
      "5716\n",
      "5717\n",
      "5720\n",
      "5722\n",
      "5729\n",
      "5739\n",
      "5748\n",
      "5752\n",
      "5754\n",
      "5755\n",
      "5767\n",
      "5772\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5792\n",
      "5793\n",
      "5795\n",
      "5804\n",
      "5805\n",
      "5823\n",
      "5826\n",
      "5827\n",
      "5830\n",
      "5833\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5841\n",
      "5846\n",
      "5857\n",
      "5861\n",
      "5862\n",
      "5865\n",
      "5869\n",
      "5871\n",
      "5872\n",
      "5875\n",
      "5884\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5896\n",
      "5904\n",
      "5906\n",
      "5911\n",
      "5915\n",
      "5919\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5928\n",
      "5931\n",
      "5938\n",
      "5939\n",
      "5944\n",
      "5957\n",
      "5960\n",
      "5964\n",
      "5976\n",
      "5979\n",
      "5983\n",
      "5989\n",
      "5991\n",
      "5992\n",
      "5994\n",
      "5996\n",
      "5997\n",
      "5999\n",
      "6004\n",
      "6006\n",
      "6008\n",
      "6016\n",
      "6018\n",
      "6020\n",
      "6025\n",
      "6026\n",
      "6029\n",
      "6036\n",
      "6039\n",
      "6044\n",
      "6048\n",
      "6057\n",
      "6060\n",
      "6061\n",
      "6064\n",
      "6066\n",
      "6071\n",
      "6072\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6087\n",
      "6099\n",
      "6104\n",
      "6106\n",
      "6111\n",
      "6112\n",
      "6114\n",
      "6116\n",
      "6118\n",
      "6120\n",
      "6122\n",
      "6127\n",
      "6136\n",
      "6141\n",
      "6142\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6150\n",
      "6159\n",
      "6161\n",
      "6168\n",
      "6170\n",
      "6172\n",
      "6173\n",
      "6181\n",
      "6182\n",
      "6190\n",
      "6198\n",
      "6200\n",
      "6202\n",
      "6211\n",
      "6214\n",
      "6218\n",
      "6220\n",
      "6234\n",
      "6238\n",
      "6242\n",
      "6244\n",
      "6245\n",
      "6264\n",
      "6266\n",
      "6268\n",
      "6272\n",
      "6275\n",
      "6276\n",
      "6280\n",
      "6292\n",
      "6299\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6306\n",
      "6317\n",
      "6323\n",
      "6328\n",
      "6331\n",
      "6333\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6344\n",
      "6350\n",
      "6351\n",
      "6356\n",
      "6357\n",
      "6364\n",
      "6375\n",
      "6379\n",
      "6381\n",
      "6384\n",
      "6391\n",
      "6393\n",
      "6395\n",
      "6397\n",
      "6399\n",
      "6401\n",
      "6407\n",
      "6417\n",
      "6421\n",
      "6426\n",
      "6428\n",
      "6429\n",
      "6432\n",
      "6436\n",
      "6444\n",
      "6453\n",
      "6458\n",
      "6464\n",
      "6465\n",
      "6469\n",
      "6474\n",
      "6477\n",
      "6484\n",
      "6489\n",
      "6495\n",
      "6501\n",
      "6503\n",
      "6504\n",
      "6510\n",
      "6526\n",
      "6529\n",
      "6535\n",
      "6536\n",
      "6539\n",
      "6542\n",
      "6544\n",
      "6551\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6564\n",
      "6565\n",
      "6568\n",
      "6571\n",
      "6579\n",
      "6581\n",
      "6583\n",
      "6584\n",
      "6593\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6602\n",
      "6603\n",
      "6605\n",
      "6608\n",
      "6609\n",
      "6615\n",
      "6622\n",
      "6623\n",
      "6625\n",
      "6631\n",
      "6635\n",
      "6647\n",
      "6649\n",
      "6652\n",
      "6657\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6671\n",
      "6672\n",
      "6675\n",
      "6685\n",
      "6688\n",
      "6691\n",
      "6695\n",
      "6696\n",
      "6710\n",
      "6716\n",
      "6717\n",
      "6724\n",
      "6727\n",
      "6730\n",
      "6734\n",
      "6736\n",
      "6737\n",
      "6744\n",
      "6747\n",
      "6751\n",
      "6755\n",
      "6758\n",
      "6760\n",
      "6761\n",
      "6766\n",
      "6767\n",
      "6769\n",
      "6772\n",
      "6774\n",
      "6777\n",
      "6778\n",
      "6779\n",
      "6786\n",
      "6788\n",
      "6791\n",
      "6792\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6805\n",
      "6808\n",
      "6810\n",
      "6815\n",
      "6818\n",
      "6820\n",
      "6827\n",
      "6829\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6848\n",
      "6849\n",
      "6851\n",
      "6852\n",
      "6857\n",
      "6859\n",
      "6861\n",
      "6862\n",
      "6869\n",
      "6880\n",
      "6889\n",
      "6892\n",
      "6898\n",
      "6900\n",
      "6901\n",
      "6909\n",
      "6910\n",
      "6911\n",
      "6913\n",
      "6924\n",
      "6928\n",
      "6929\n",
      "6931\n",
      "6938\n",
      "6952\n",
      "6959\n",
      "6961\n",
      "6970\n",
      "6974\n",
      "6975\n",
      "6978\n",
      "6980\n",
      "6986\n",
      "6990\n",
      "6992\n",
      "6994\n",
      "7003\n",
      "7009\n",
      "7012\n",
      "7015\n",
      "7018\n",
      "7019\n",
      "7020\n",
      "7021\n",
      "7039\n",
      "7042\n",
      "7049\n",
      "7050\n",
      "7056\n",
      "7057\n",
      "7058\n",
      "7061\n",
      "7062\n",
      "7064\n",
      "7065\n",
      "7066\n",
      "7067\n",
      "7069\n",
      "7072\n",
      "7073\n",
      "7074\n",
      "7075\n",
      "7078\n",
      "7081\n",
      "7083\n",
      "7091\n",
      "7101\n",
      "7111\n",
      "7121\n",
      "7125\n",
      "7130\n",
      "7131\n",
      "7140\n",
      "7142\n",
      "7146\n",
      "7147\n",
      "7151\n",
      "7165\n",
      "7167\n",
      "7173\n",
      "7175\n",
      "7179\n",
      "7180\n",
      "7192\n",
      "7203\n",
      "7214\n",
      "7215\n",
      "7218\n",
      "7221\n",
      "7225\n",
      "7230\n",
      "7231\n",
      "7236\n",
      "7240\n",
      "7243\n",
      "7244\n",
      "7245\n",
      "7246\n",
      "7256\n",
      "7257\n",
      "7260\n",
      "7261\n",
      "7265\n",
      "7268\n",
      "7270\n",
      "7273\n",
      "7286\n",
      "7290\n",
      "7294\n",
      "7296\n",
      "7297\n",
      "7300\n",
      "7309\n",
      "7310\n",
      "7313\n",
      "7317\n",
      "7319\n",
      "7330\n",
      "7334\n",
      "7337\n",
      "7338\n",
      "7344\n",
      "7347\n",
      "7349\n",
      "7354\n",
      "7355\n",
      "7356\n",
      "7362\n",
      "7366\n",
      "7369\n",
      "7377\n",
      "7380\n",
      "7383\n",
      "7388\n",
      "7389\n",
      "7411\n",
      "7416\n",
      "7417\n",
      "7420\n",
      "7424\n",
      "7431\n",
      "7432\n",
      "7433\n",
      "7435\n",
      "7436\n",
      "7437\n",
      "7441\n",
      "7450\n",
      "7454\n",
      "7468\n",
      "7469\n",
      "7471\n",
      "7473\n",
      "7477\n",
      "7479\n",
      "7484\n",
      "7492\n",
      "7494\n",
      "7500\n",
      "7504\n",
      "7505\n",
      "7517\n",
      "7521\n",
      "7522\n",
      "7527\n",
      "7532\n",
      "7541\n",
      "7545\n",
      "7547\n",
      "7553\n",
      "7558\n",
      "7560\n",
      "7562\n",
      "7565\n",
      "7571\n",
      "7594\n",
      "7595\n",
      "7602\n",
      "7607\n",
      "7610\n",
      "7612\n",
      "7617\n",
      "7620\n",
      "7626\n",
      "7638\n",
      "7641\n",
      "7644\n",
      "7646\n",
      "7663\n",
      "7666\n",
      "7668\n",
      "7672\n",
      "7681\n",
      "7682\n",
      "7684\n",
      "7688\n",
      "7691\n",
      "7698\n",
      "7701\n",
      "7703\n",
      "7706\n",
      "7707\n",
      "7709\n",
      "7712\n",
      "7714\n",
      "7716\n",
      "7723\n",
      "7727\n",
      "7728\n",
      "7729\n",
      "7730\n",
      "7732\n",
      "7733\n",
      "7744\n",
      "7748\n",
      "7754\n",
      "7756\n",
      "7762\n",
      "7768\n",
      "7772\n",
      "7778\n",
      "7790\n",
      "7791\n",
      "7792\n",
      "7802\n",
      "7812\n",
      "7813\n",
      "7817\n",
      "7818\n",
      "7822\n",
      "7823\n",
      "7824\n",
      "7831\n",
      "7842\n",
      "7844\n",
      "7845\n",
      "7848\n",
      "7849\n",
      "7855\n",
      "7863\n",
      "7864\n",
      "7867\n",
      "7873\n",
      "7879\n",
      "7885\n",
      "7898\n",
      "7903\n",
      "7914\n",
      "7915\n",
      "7916\n",
      "7917\n",
      "7921\n",
      "7926\n",
      "7929\n",
      "7935\n",
      "7936\n",
      "7939\n",
      "7942\n",
      "7943\n",
      "7955\n",
      "7958\n",
      "7963\n",
      "7969\n",
      "7970\n",
      "7974\n",
      "7977\n",
      "7980\n",
      "7983\n",
      "7985\n",
      "7986\n",
      "7987\n",
      "7989\n",
      "8001\n",
      "8010\n",
      "8012\n",
      "8021\n",
      "8025\n",
      "8030\n",
      "8033\n",
      "8036\n",
      "8044\n",
      "8045\n",
      "8048\n",
      "8058\n",
      "8060\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8066\n",
      "8068\n",
      "8075\n",
      "8081\n",
      "8083\n",
      "8090\n",
      "8094\n",
      "8113\n",
      "8114\n",
      "8117\n",
      "8119\n",
      "8127\n",
      "8128\n",
      "8129\n",
      "8130\n",
      "8136\n",
      "8138\n",
      "8139\n",
      "8141\n",
      "8143\n",
      "8144\n",
      "8151\n",
      "8158\n",
      "8162\n",
      "8165\n",
      "8168\n",
      "8174\n",
      "8179\n",
      "8182\n",
      "8197\n",
      "8208\n",
      "8220\n",
      "8222\n",
      "8224\n",
      "8226\n",
      "8229\n",
      "8233\n",
      "8250\n",
      "8260\n",
      "8267\n",
      "8274\n",
      "8287\n",
      "8288\n",
      "8293\n",
      "8308\n",
      "8309\n",
      "8310\n",
      "8313\n",
      "8322\n",
      "8329\n",
      "8349\n",
      "8357\n",
      "8358\n",
      "8361\n",
      "8369\n",
      "8378\n",
      "8382\n"
     ]
    }
   ],
   "source": [
    "temp = (pred - test_labels)\n",
    "for i in range(len(temp)):\n",
    "    if temp[i] != 0: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- make own loss function for randomforest\n",
    "- mess with binary distribution?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30759\n",
      "30759\n",
      "30759\n",
      "30759\n"
     ]
    }
   ],
   "source": [
    "images = df.iloc[:, :440].to_numpy()\n",
    "primary_labels = df.iloc[:,441].to_numpy()\n",
    "secondary_labels = df.iloc[:,442].to_numpy()\n",
    "# Split into training and testing sets\n",
    "train_images_p, train_labels_p, test_images_p, test_labels_p = split_data(images, primary_labels)\n",
    "train_images_s, train_labels_s, test_images_s, test_labels_s = split_data(images, secondary_labels)\n",
    "images = df.iloc[:, :443].to_numpy()\n",
    "train_images_fs, train_labels_fs, test_images_fs, test_labels_fs = split_data(images, secondary_labels)\n",
    "x = np.insert(np.arange(442),0,443)\n",
    "images = df.iloc[:, x].to_numpy()\n",
    "train_images_fp, train_labels_fp, test_images_fp, test_labels_fp = split_data(images, primary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Flux, predicting Primaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mod = RandomForestClassifier(random_state=0)\n",
    "p_mod.fit(train_images_p, train_labels_p)\n",
    "p_acc = p_mod.score(test_images_p, test_labels_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800780234070221"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Flux, predicting Secondaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mod = RandomForestClassifier(random_state=0)\n",
    "s_mod.fit(train_images_s, train_labels_s)\n",
    "s_acc = s_mod.score(test_images_s, test_labels_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6426527958387517"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Flux and Primaries, Predicting Secondaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_mod = RandomForestClassifier(random_state=0)\n",
    "fs_mod.fit(train_images_fs, train_labels_fs)\n",
    "fs_acc = fs_mod.score(test_images_fs, test_labels_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195058517555267"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Flux and Secondaries, Predicting Primaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mod = RandomForestClassifier(random_state=0)\n",
    "fp_mod.fit(train_images_fp, train_labels_fp)\n",
    "fp_acc = fp_mod.score(test_images_fp, test_labels_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347204161248375"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mod = RandomForestClassifier(random_state=0)\n",
    "p_mod.fit(train_images_p, train_labels_p)\n",
    "p_acc = p_mod.score(test_images_p, test_labels_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6430429128738622 0.9227568270481145\n"
     ]
    }
   ],
   "source": [
    "print(p_acc, s_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test(rf):\n",
    "    bin_results = np.zeros((23,23))\n",
    "    for primary in range(16,39):\n",
    "        for secondary in range(primary, 39):\n",
    "            data = bin_df.loc[(bin_df['primary_type'] == primary) & (bin_df['secondary_type'] == secondary)]\n",
    "            \n",
    "            images = data.iloc[:,:440].to_numpy()\n",
    "            \n",
    "            try:\n",
    "                accuracy = rf.score(images, data['secondary_type'].to_numpy())\n",
    "            except:\n",
    "                accuracy = 0\n",
    "\n",
    "            bin_results[primary - 16, secondary - 16] = accuracy\n",
    "        \n",
    "    acc_map(bin_results)\n",
    "    return bin_results\n",
    "\n",
    "def acc_map(results, title = 'Secondary Prediction Accuracy'):\n",
    "    plt.figure(figsize = (8,7), facecolor='white')\n",
    "    ax = sns.heatmap(results, cmap = \"mako\")\n",
    "    labels = ['M6','M7','M8','M9','L0','L1','L2','L3','L4','L5','L6','L7','L8','L9','T0','T1','T2','T3','T4','T5','T6','T7','T8']\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.patch.set_edgecolor('black')  \n",
    "    ax.patch.set_linewidth('10') \n",
    "    ax.set_ylabel('Primary')\n",
    "    ax.set_xlabel('Seconday')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = grid_test(s_mod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f00498b9bc416871af40540d24511ca2f0547b4670375674646df8758df38473"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
