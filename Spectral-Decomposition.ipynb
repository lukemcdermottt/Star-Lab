{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I just load in everything, delete stuff if you want\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,RepeatedKFold, GridSearchCV,  RandomizedSearchCV\n",
    "import math\n",
    "from data import *\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO based on importance:\n",
    "- Create separate models for system types\n",
    "- Add SNR to images?\n",
    "- Sample Train/Test split better to maintain class distribution\n",
    "- Cross Validation\n",
    "- Try out more Multivariate Regression (bc continuous & multi-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/Users/lukemcdermott/Desktop/Physics/spectral_templates_data_version_june20.h5', key = '/binaries')\n",
    "bin_df = pd.read_hdf('/Users/lukemcdermott/Desktop/Physics/spectral_templates_data_version_june20.h5', key = '/binaries')\n",
    "df = df.loc[df['primary_type'] <= df['secondary_type']]\n",
    "display(df)\n",
    "#x = np.insert(np.arange(441), 0, -1)   #Uncomment to add system type\n",
    "x = np.arange(441)\n",
    "images = df.iloc[:, x].to_numpy()\n",
    "labels = df.iloc[:, 441:443].to_numpy()\n",
    "labels_flat = np.zeros((len(labels)))\n",
    "for idx, i in enumerate(labels):\n",
    "    labels_flat[idx] = 24*(int(i[0]-16)) + int((i[1]-16))\n",
    "#Convert 2D labels into 1D Discrete Classes\n",
    "    \n",
    "idx = np.random.choice(np.arange(len(images)), 35000, replace=False)\n",
    "images_sample = images[idx]\n",
    "labels_sample = labels_flat[idx]\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_images, train_labels, test_images, test_labels = split_data(images_sample, labels_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 1000, solver='lbfgs')\n",
    "clf.fit(train_images, train_labels)\n",
    "clf.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing 1D Discrete Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_flat = clf.predict(test_images)\n",
    "#unflatten\n",
    "outputs = np.zeros((len(outputs_flat), 2)).astype(int)\n",
    "lab = np.zeros((len(test_labels), 2)).astype(int)\n",
    "\n",
    "for idx, val in enumerate(outputs_flat):\n",
    "    #labels_flat[idx] = 24*(int(i[0]-16)) + int((i[1]-16))\n",
    "    outputs[idx,0] = val // 24 + 16\n",
    "    outputs[idx,1] = val % 24 + 16\n",
    "\n",
    "for idx, val in enumerate(test_labels):\n",
    "    #labels_flat[idx] = 24*(int(i[0]-16)) + int((i[1]-16))\n",
    "    lab[idx,0] = val // 24 + 16\n",
    "    lab[idx,1] = val % 24 + 16\n",
    "\n",
    "diff = lab - outputs\n",
    "\n",
    "#SMSE Loss\n",
    "print('primary loss', math.sqrt(sklearn.metrics.mean_squared_error(lab[:,0], outputs[:,0])))\n",
    "print('secondary loss', math.sqrt(sklearn.metrics.mean_squared_error(lab[:,1], outputs[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for idx, val in enumerate(outputs):\n",
    "    try:\n",
    "        predictions[lab[idx,0], lab[idx,1]].append(val)\n",
    "    except:\n",
    "        predictions[lab[idx,0], lab[idx,1]] = []\n",
    "\n",
    "mean_pred = {}\n",
    "for pair in predictions:\n",
    "    predictions[pair] = np.array(predictions[pair])\n",
    "    #print(np.shape(predictions[pair]))\n",
    "    if len(predictions[pair]) != 0:\n",
    "        mean_pred[pair] = np.mean(predictions[pair],axis = 0)\n",
    "    else:\n",
    "        print('No test values for:', pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(p, s):\n",
    "    results = np.array(predictions[(p,s)])\n",
    "    plt.figure(facecolor = 'white')\n",
    "    plt.xticks(np.arange(16,40))\n",
    "    plt.hist(results[:,0], range=[16,40], bins = 23, color = 'blue', alpha = .5, label = 'Primary Prediction')\n",
    "    plt.hist(results[:,1], range=[16,40], bins = 23, color = 'red', alpha = .5, label = 'Secondary Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def acc_map(results, title = 'Secondary Prediction Accuracy', annotation = False):\n",
    "    plt.figure(figsize = (8,7), facecolor='white')\n",
    "    ax = sns.heatmap(results, cmap = \"mako\", annot = annotation)\n",
    "    labels = ['M6','M7','M8','M9','L0','L1','L2','L3','L4','L5','L6','L7','L8','L9','T0','T1','T2','T3','T4','T5','T6','T7','T8']\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.patch.set_edgecolor('black')  \n",
    "    ax.patch.set_linewidth('10') \n",
    "    ax.set_ylabel('Primary')\n",
    "    ax.set_xlabel('Secondary')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_mean = np.zeros((23,23))\n",
    "sec_mean = np.zeros((23,23))\n",
    "\n",
    "for primary in range(16,39):\n",
    "    for secondary in range(primary, 39):\n",
    "        try:\n",
    "            mu = mean_pred[(primary,secondary)]\n",
    "        except:\n",
    "            mu = [0,0]\n",
    "        pri_mean[primary-16,secondary-16] = mu[0]\n",
    "        sec_mean[primary-16,secondary-16] = mu[1]\n",
    "        \n",
    "acc_map(pri_mean, 'Mean of Primary Predictions', annotation = True)\n",
    "acc_map(sec_mean, 'Mean of Secondary Predictions', annotation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_mean = np.zeros((23,23))\n",
    "sec_mean = np.zeros((23,23))\n",
    "\n",
    "for primary in range(16,39):\n",
    "    for secondary in range(primary, 39):\n",
    "        try:\n",
    "            mu = abs(mean_pred[(primary,secondary)] - (primary,secondary))\n",
    "        except:\n",
    "            mu = [0,0]\n",
    "        pri_mean[primary-16,secondary-16] = mu[0]\n",
    "        sec_mean[primary-16,secondary-16] = mu[1]\n",
    "        \n",
    "acc_map(pri_mean, 'Mean Difference of Primary Predictions')\n",
    "acc_map(sec_mean, 'Mean Difference of Secondary Predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f00498b9bc416871af40540d24511ca2f0547b4670375674646df8758df38473"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
